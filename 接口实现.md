## ASR

### AsrActivity

```java
import android.app.Activity;
import android.os.Bundle;
import android.util.Log;
import android.view.View;

public class AsrActivity extends Activity {
    private static final String TAG = "AsrActivity";
    private AudioProcessor audioProcessor;
    private long sessionId;

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_asr);

        // 初始化 ASR 相关组件
        AsrRequest.SampleRate sampleRate = AsrRequest.SampleRate.Rate16K;
        int channel = 1;
        sessionId = startAsrSession(sampleRate, channel);

        // 初始化音频处理器
        audioProcessor = new AudioProcessor();
    }

    // 开始录音和识别
    public void onStartRecognition(View view) {
        // 开始录音
        audioProcessor.startRecording();
    }

    // 结束录音和识别
    public void onStopRecognition(View view) {
        // 停止录音
        audioProcessor.stopRecording();

        // 结束识别会话，获取识别结果
        String result = endAsrSession();

        // 处理识别结果
        Log.d(TAG, "识别结果：" + result);
    }

    private long startAsrSession(AsrRequest.SampleRate sampleRate, int channel) {
        // 调用实际的 startAsrSession 方法，返回会话id
        // 示例中使用虚构的值，你需要根据实际情况调用相应的 ASR SDK 方法
        return ASRSDK.startAsrSession(sampleRate, channel);
    }

    private void asr(byte[] data) {
        // 调用实际的 asr 方法，传入 PCM 数据
        // 示例中使用虚构的值，你需要根据实际情况调用相应的 ASR SDK 方法
        String recognitionResult = ASRSDK.asr(data);

        // 处理识别结果，这里可以根据实际需求进行处理
        Log.d(TAG, "实时识别结果：" + recognitionResult);
    }

    private String endAsrSession() {
        // 调用实际的 endAsrSession 方法，结束本次识别会话并返回识别结果
        // 示例中使用虚构的值，你需要根据实际情况调用相应的 ASR SDK 方法
        return ASRSDK.endAsrSession();
    }
}
```

添加了对 `asr(byte[] data)` 方法的调用，以便在实时录音的过程中将 PCM 数据传递给语音识别引擎。请记得替换示例中的 `ASRSDK` 调用为你实际使用的 ASR SDK 的相应方法。



### AudioProcessor

在 Android 中，要从麦克风获取音频数据，通常需要使用 `AudioRecord` 类。在 `AudioProcessor` 类中，你已经有了启动和停止录音的逻辑，我们可以在录音的过程中获取 PCM 数据并调用 `asr` 方法。以下是相应的修改：

```java
import android.media.AudioFormat;
import android.media.AudioRecord;
import android.media.MediaRecorder;
import android.util.Log;

public class AudioProcessor {
    private static final String TAG = "AudioProcessor";
    private AudioRecord audioRecord;

    public AudioProcessor() {
        // 初始化 AudioRecord
        int bufferSize = AudioRecord.getMinBufferSize(SAMPLE_RATE, CHANNEL_CONFIG, AUDIO_FORMAT);
        audioRecord = new AudioRecord(MediaRecorder.AudioSource.MIC, SAMPLE_RATE, CHANNEL_CONFIG, AUDIO_FORMAT, bufferSize);
    }

    public void startRecording() {
        if (audioRecord.getState() != AudioRecord.STATE_INITIALIZED) {
            Log.e(TAG, "AudioRecord initialization failed");
            return;
        }

        audioRecord.startRecording();

        // 开启录制线程
        new Thread(new Runnable() {
            @Override
            public void run() {
                byte[] buffer = new byte[1024]; // 根据实际需求设置合适的缓冲区大小

                while (audioRecord.getRecordingState() == AudioRecord.RECORDSTATE_RECORDING) {
                    int bytesRead = audioRecord.read(buffer, 0, buffer.length);
                    if (bytesRead > 0) {
                        // 将 PCM 数据传递给识别引擎
                        asr(buffer);
                    }
                }
            }
        }).start();
    }

    public void stopRecording() {
        if (audioRecord.getState() == AudioRecord.STATE_INITIALIZED) {
            audioRecord.stop();
            audioRecord.release();
        }
    }

    private void asr(byte[] data) {
        // 将 PCM 数据传递给语音识别引擎
        // 调用相应的语音识别方法，例如：asr(data);
        // 在这里，你可以将 data 传递给 AsrActivity 中的相应方法
        ((AsrActivity) context).asr(data);
    }
}
```

在上述代码中，通过将 `context` 传递给 `AudioProcessor`，我们可以在 `asr` 方法中调用 `AsrActivity` 中的 `asr` 方法。请确保你在 `AsrActivity` 中正确设置 `context`，以便在 `AudioProcessor` 中使用。